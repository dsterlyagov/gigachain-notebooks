{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d492b507-4e30-48b9-b267-0a8b7d9b036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "auth = 'YzZmOGRmMzktOGI1Zi00MmZlLWFjYjEtOWQ2OTc0NjRiN2VlOjNkODEwNjQzLWQ5ODItNDlhMS04MGQ4LWU4ZmU1ODU3YTllMw=='\n",
    "# Авторизация в сервисе GigaChat\n",
    "bot_token = '7167554009:AAF2AWQ1yfORDhDp1JFf2Mo0s3WZkWpOVeY'\n",
    "chat = GigaChat(credentials=auth, verify_ssl_certs=False)\n",
    "conversation1 = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd09e7c-3fe8-4d9f-a6a6-b03b4df9fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
      "\n",
      "Текущий разговор:\n",
      "\n",
      "Human: Привет! Меня зовут Дмитрий я сейчас программирую на Python\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Привет, Дмитрий! Я рад познакомиться с вами. Как продвигается ваш проект?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.predict(input='Привет! Меня зовут Дмитрий я сейчас программирую на Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881ddd15-c045-4943-8d63-b6d41a1e5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий я сейчас программирую на Python\n",
      "AI: Привет, Дмитрий! Я рад познакомиться с вами. Как продвигается ваш проект?\n",
      "Human: Какая языковая модель самая лучшая?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Это зависит от ваших целей и предпочтений. Некоторые популярные модели включают GPT-3, T5, BERT, Transformer и многие другие. Каждая модель имеет свои сильные и слабые стороны, поэтому выбор может быть индивидуальным.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.predict(input='Какая языковая модель самая лучшая?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647ccac6-d208-4edc-a183-157fab3127f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий я сейчас программирую на Python\n",
      "AI: Привет, Дмитрий! Я рад познакомиться с вами. Как продвигается ваш проект?\n",
      "Human: Какая языковая модель самая лучшая?\n",
      "AI: Это зависит от ваших целей и предпочтений. Некоторые популярные модели включают GPT-3, T5, BERT, Transformer и многие другие. Каждая модель имеет свои сильные и слабые стороны, поэтому выбор может быть индивидуальным.\n",
      "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'В этом случае, возможно, вам подойдет русскоязычная модель ruGPT3, которая является бесплатной и доступна для использования. Однако, стоит отметить, что качество генерации текста может отличаться в зависимости от конкретной модели и ее настройки.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c10fc77-d26d-4551-b762-600ce6a931c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий я сейчас программирую на Python\n",
      "AI: Привет, Дмитрий! Я рад познакомиться с вами. Как продвигается ваш проект?\n",
      "Human: Какая языковая модель самая лучшая?\n",
      "AI: Это зависит от ваших целей и предпочтений. Некоторые популярные модели включают GPT-3, T5, BERT, Transformer и многие другие. Каждая модель имеет свои сильные и слабые стороны, поэтому выбор может быть индивидуальным.\n",
      "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском\n",
      "AI: В этом случае, возможно, вам подойдет русскоязычная модель ruGPT3, которая является бесплатной и доступна для использования. Однако, стоит отметить, что качество генерации текста может отличаться в зависимости от конкретной модели и ее настройки.\n",
      "Human: Как меня зовут и чем я занимаюсь?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Вы можете ввести эту информацию самостоятельно, чтобы получить более точный ответ.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.predict(input='Как меня зовут и чем я занимаюсь?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813dcc8a-e068-4cb1-983f-a8f7c3e59dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ce74b1-4b0f-4add-87b4-ffcf34d7ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1 = GigaChat(credentials=auth, verify_ssl_certs=False)\n",
    "conversation2 = ConversationChain(\n",
    "    llm=chat_1,\n",
    "    verbose=True,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory( llm=chat_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec13925-f63e-4a0f-9f62-6e69ad42e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
      "\n",
      "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
      "\n",
      "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
      "\n",
      "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
      "\n",
      "Контекст:\n",
      "{'Gigachat': '', 'Python': ''}\n",
      "\n",
      "Текущий разговор:\n",
      "\n",
      "Последняя строка:\n",
      "Человек: Привет! Меня зовут Дмитрий. Я сейчас записываю видео про Gigachat и Python\n",
      "Ты:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Привет, Дмитрий! Рад познакомиться. Чем я могу помочь?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Привет! Меня зовут Дмитрий. Я сейчас записываю видео про Gigachat и Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca3f2cc-2b6f-4078-9956-3964563136c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
      "\n",
      "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
      "\n",
      "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
      "\n",
      "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
      "\n",
      "Контекст:\n",
      "{'Gigachat': 'Дмитрий записывает видео про Gigachat и Python.'}\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий. Я сейчас записываю видео про Gigachat и Python\n",
      "AI: Привет, Дмитрий! Рад познакомиться. Чем я могу помочь?\n",
      "Последняя строка:\n",
      "Человек: Какая большая языковая модель самая лучшая?\n",
      "Ты:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Это сложный вопрос, так как выбор лучшей языковой модели зависит от конкретных потребностей и целей пользователя. Некоторые популярные модели включают GPT-3, BERT, T5, Transformer и другие. Однако важно отметить, что результаты могут сильно варьироваться в зависимости от контекста использования и требований задачи.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Какая большая языковая модель самая лучшая?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6aa27db-b536-480d-aaeb-60f6095dc701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
      "\n",
      "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
      "\n",
      "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
      "\n",
      "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
      "\n",
      "Контекст:\n",
      "{'русская': ''}\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий. Я сейчас записываю видео про Gigachat и Python\n",
      "AI: Привет, Дмитрий! Рад познакомиться. Чем я могу помочь?\n",
      "Human: Какая большая языковая модель самая лучшая?\n",
      "AI: Это сложный вопрос, так как выбор лучшей языковой модели зависит от конкретных потребностей и целей пользователя. Некоторые популярные модели включают GPT-3, BERT, T5, Transformer и другие. Однако важно отметить, что результаты могут сильно варьироваться в зависимости от контекста использования и требований задачи.\n",
      "Последняя строка:\n",
      "Человек: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
      "Ты:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Существует несколько бесплатных русскоязычных языковых моделей, таких как ruGPT3, ruT5, ruBERT и другие. Они могут быть полезными инструментами для тех, кто хочет работать с русским языком. Однако стоит учесть, что качество их работы может отличаться от коммерческих моделей, и они могут не подходить для всех задач.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a913f9c-d017-431e-8d3b-f7b145a75d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
      "\n",
      "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
      "\n",
      "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
      "\n",
      "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
      "\n",
      "Контекст:\n",
      "{'Дмитрий': ''}\n",
      "\n",
      "Текущий разговор:\n",
      "Human: Привет! Меня зовут Дмитрий. Я сейчас записываю видео про Gigachat и Python\n",
      "AI: Привет, Дмитрий! Рад познакомиться. Чем я могу помочь?\n",
      "Human: Какая большая языковая модель самая лучшая?\n",
      "AI: Это сложный вопрос, так как выбор лучшей языковой модели зависит от конкретных потребностей и целей пользователя. Некоторые популярные модели включают GPT-3, BERT, T5, Transformer и другие. Однако важно отметить, что результаты могут сильно варьироваться в зависимости от контекста использования и требований задачи.\n",
      "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
      "AI: Существует несколько бесплатных русскоязычных языковых моделей, таких как ruGPT3, ruT5, ruBERT и другие. Они могут быть полезными инструментами для тех, кто хочет работать с русским языком. Однако стоит учесть, что качество их работы может отличаться от коммерческих моделей, и они могут не подходить для всех задач.\n",
      "Последняя строка:\n",
      "Человек: Как меня зовут и чем я занимаюсь?\n",
      "Ты:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Вас зовут Дмитрий, и вы сейчас записываете видео про Gigachat и Python.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.predict(input='Как меня зовут и чем я занимаюсь?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41f145d-648e-4e8b-85ba-bda574b4d155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gigachat': 'Человек интересуется лучшей языковой моделью.',\n",
       " 'Python': 'Python - язык программирования, используемый в видео про Gigachat.',\n",
       " 'русская': 'Русский',\n",
       " 'Дмитрий': 'Дмитрий'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b945e71-8c41-486e-80c2-659bfdefe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь для хранения \n",
    "user_conversations = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ae4b4c-3259-4a1b-9455-71b8115bb5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "from time import sleep\n",
    "\n",
    "bot = telebot.TeleBot(bot_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87952f0b-dba3-462e-a689-d269305806e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GigaChat(credentials=auth, verify_ssl_certs=False)\n",
    "conversation_2 = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c554bc-379e-4b2c-9206-9e8f604ae58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для автоматического ответа в случае нетекстового сообщения\n",
    "@bot.message_handler(content_types=['audio',\n",
    "                                    'video',\n",
    "                                    'document',\n",
    "                                    'photo',\n",
    "                                    'sticker',\n",
    "                                    'voice',\n",
    "                                    'location',\n",
    "                                    'contact'])\n",
    "\n",
    "def not_text(message):\n",
    "    user_id = message.chat.id\n",
    "    bot.send_message(user_id, 'Я работаю только с текстовыми данными')\n",
    "\n",
    "# Функция обрабатывающая текстовые сообщения \n",
    "@bot.message_handler(content_types=['text'])\n",
    "def handle_text_message(message):\n",
    "    user_id = message.chat.id\n",
    "\n",
    "    # проверка, существует ли уже ConversationBufferMemory для данного пользователя\n",
    "    if user_id not in user_conversations:\n",
    "        user_conversations[user_id] = ConversationBufferMemory()\n",
    "\n",
    "    # Обновление конфигурации ConversationChain Для текущего пользователя\n",
    "    conversation_2.memory = user_conversations[user_id]\n",
    "\n",
    "    # Получение и отправка ответа через Gigachat\n",
    "    response = conversation_2.predict(input=message.text)\n",
    "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327eedd0-312d-4aec-b4ff-fc1104304a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск бота\n",
    "bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30cfd8-9ffa-450e-ba5f-15b0d8aa24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template= '''\n",
    "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать \\\n",
    "на вопросы по истории. Если задают вопросы по другим темам, говори что это \\\n",
    "тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \\\n",
    "\\n\\nТекущий разговор:\\n{history}\\nHuman: {input}\\nAI:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_3 = ConversationChain(llm=llm,\n",
    "                                 verbose=True,\n",
    "                                 memory=ConversationBufferMemory())\n",
    "conversation.prompt.template = template"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53352e-f0bd-4678-9317-0b1762f48379",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_3 = ConversationChain(llm=llm,\n",
    "                                 verbose=True,\n",
    "                                 memory=ConversationBufferMemory())\n",
    "conversation.prompt.template = template"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}